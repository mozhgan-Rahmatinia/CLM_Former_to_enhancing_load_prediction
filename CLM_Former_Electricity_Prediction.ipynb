{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 350,
     "status": "ok",
     "timestamp": 1711876795329,
     "user": {
      "displayName": "deep_ learninng",
      "userId": "04264285591991528950"
     },
     "user_tz": -210
    },
    "id": "SXJR6oUF5bAx",
    "outputId": "7a0ca58b-36cd-4624-9e57-4b8f02337ea0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2268,
     "status": "ok",
     "timestamp": 1711876798057,
     "user": {
      "displayName": "deep_ learninng",
      "userId": "04264285591991528950"
     },
     "user_tz": -210
    },
    "id": "pYuhwN0C5Z_j",
    "outputId": "19d4b2d0-0cc1-43aa-b705-5876066456e8"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1711876798058,
     "user": {
      "displayName": "deep_ learninng",
      "userId": "04264285591991528950"
     },
     "user_tz": -210
    },
    "id": "Tkd3Eyqb5Z_m"
   },
   "outputs": [],
   "source": [
    "\n",
    "#os.chdir('/content/drive/MyDrive/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1711876798058,
     "user": {
      "displayName": "deep_ learninng",
      "userId": "04264285591991528950"
     },
     "user_tz": -210
    },
    "id": "qm8vaIoe6BrX",
    "outputId": "f78f42de-b7f0-44a5-bd4b-02a6b5a966a6"
   },
   "outputs": [],
   "source": [
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1711876798060,
     "user": {
      "displayName": "deep_ learninng",
      "userId": "04264285591991528950"
     },
     "user_tz": -210
    },
    "id": "VdhHlWOI5Z_n"
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "if not 'CLM_Former' in sys.path:\n",
    "    sys.path += ['CLM_Former']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8c1kAdk5Z_n"
   },
   "source": [
    "# Experiments: Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1711876798062,
     "user": {
      "displayName": "deep_ learninng",
      "userId": "04264285591991528950"
     },
     "user_tz": -210
    },
    "id": "crf5OsxV5Z_o"
   },
   "outputs": [],
   "source": [
    "from utils.tools import dotdict\n",
    "from exp.exp_main import Exp_Main\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1711876798063,
     "user": {
      "displayName": "deep_ learninng",
      "userId": "04264285591991528950"
     },
     "user_tz": -210
    },
    "id": "Ev6f0CP25Z_q",
    "outputId": "01c2a0ea-09ae-4196-c301-abf9b6c927eb"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "from exp.exp_main import Exp_Main#exp stands for experiments\n",
    "import random\n",
    "import numpy as np\n",
    "from utils.tools import dotdict\n",
    "\n",
    "fix_seed = 2021\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Autoformer & Transformer family for Time Series Forecasting')\n",
    "\n",
    "# basic config\n",
    "parser.add_argument('--is_training', type=int, required=True, default=1, help='status')\n",
    "parser.add_argument('--model_id', type=str, required=True, default='test', help='model id')\n",
    "parser.add_argument('--model', type=str, required=True, default='Autoformer',\n",
    "                    help='model name, options: [Autoformer, Informer, Transformer]')\n",
    "\n",
    "# data loader\n",
    "parser.add_argument('--data', type=str, required=True, default='ETTm1', help='dataset type')\n",
    "parser.add_argument('--root_path', type=str, default='./data/ETT/', help='root path of the data file')\n",
    "parser.add_argument('--data_path', type=str, default='ETTh1.csv', help='data file')\n",
    "parser.add_argument('--features', type=str, default='M',\n",
    "                    help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')\n",
    "parser.add_argument('--target', type=str, default='OT', help='target feature in S or MS task')\n",
    "parser.add_argument('--freq', type=str, default='h',\n",
    "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "parser.add_argument('--checkpoints', type=str, default='./checkpoints/', help='location of model checkpoints')\n",
    "\n",
    "# forecasting task\n",
    "parser.add_argument('--seq_len', type=int, default=96, help='input sequence length')\n",
    "parser.add_argument('--label_len', type=int, default=48, help='start token length')\n",
    "parser.add_argument('--pred_len', type=int, default=24, help='prediction sequence length')\n",
    "\n",
    "# model define\n",
    "parser.add_argument('--bucket_size', type=int, default=4, help='for Reformer')\n",
    "parser.add_argument('--n_hashes', type=int, default=4, help='for Reformer')\n",
    "parser.add_argument('--enc_in', type=int, default=7, help='encoder input size')\n",
    "parser.add_argument('--dec_in', type=int, default=7, help='decoder input size')\n",
    "parser.add_argument('--c_out', type=int, default=7, help='output size')\n",
    "parser.add_argument('--d_model', type=int, default=512, help='dimension of model')\n",
    "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
    "parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')\n",
    "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')\n",
    "parser.add_argument('--d_ff', type=int, default=2048, help='dimension of fcn')\n",
    "parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')\n",
    "parser.add_argument('--factor', type=int, default=1, help='attn factor')\n",
    "parser.add_argument('--distil', action='store_false',\n",
    "                    help='whether to use distilling in encoder, using this argument means not using distilling',\n",
    "                    default=True)\n",
    "parser.add_argument('--dropout', type=float, default=0.05, help='dropout')\n",
    "parser.add_argument('--embed', type=str, default='timeF',\n",
    "                    help='time features encoding, options:[timeF, fixed, learned]')\n",
    "parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
    "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in encoder')\n",
    "parser.add_argument('--do_predict', action='store_true', help='whether to predict unseen future data')\n",
    "\n",
    "# optimization\n",
    "parser.add_argument('--num_workers', type=int, default=10, help='data loader num workers')\n",
    "parser.add_argument('--itr', type=int, default=2, help='experiments times')\n",
    "parser.add_argument('--train_epochs', type=int, default=10, help='train epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='batch size of train input data')\n",
    "parser.add_argument('--patience', type=int, default=3, help='early stopping patience')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate')\n",
    "parser.add_argument('--des', type=str, default='test', help='exp description')\n",
    "parser.add_argument('--loss', type=str, default='mse', help='loss function')\n",
    "parser.add_argument('--lradj', type=str, default='type1', help='adjust learning rate')\n",
    "parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)\n",
    "\n",
    "# GPU\n",
    "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
    "parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
    "parser.add_argument('--devices', type=str, default='0,1,2,3', help='device ids of multile gpus')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args = dotdict()\n",
    "args.target = 'OT'\n",
    "args.des = 'test'\n",
    "args.dropout = 0.05\n",
    "args.num_workers = 10\n",
    "args.gpu = 0\n",
    "args.lradj = 'type1'\n",
    "args.devices = '0'\n",
    "args.use_gpu = True\n",
    "args.use_multi_gpu = False\n",
    "args.freq = 'h'\n",
    "args.checkpoints = './checkpoints/'\n",
    "args.bucket_size = 4\n",
    "args.n_hashes = 4\n",
    "args.is_trainging = True\n",
    "args.root_path = './data/electricity/'\n",
    "args.data_path ='electricity.csv'\n",
    "args.model_id='New_electricity_128_192' \n",
    "args.model = 'CLM_Former'\n",
    "args.data = 'custom'\n",
    "args.features = 'M'    # M, MS, S\n",
    "args.seq_len = 128\n",
    "args.label_len = 48\n",
    "args.pred_len = 192   # 96, 192, 336\n",
    "args.e_layers = 4\n",
    "args.d_layers = 4\n",
    "args.n_heads = 8\n",
    "args.factor = 3\n",
    "args.enc_in = 321\n",
    "args.dec_in =321\n",
    "args.c_out = 321\n",
    "args.d_model = 512\n",
    "args.des = 'Exp'\n",
    "args.itr = 1\n",
    "args.d_ff = 2048\n",
    "args.moving_avg = 25\n",
    "args.factor = 1\n",
    "args.distil = True\n",
    "args.output_attention = False\n",
    "args.patience= 3\n",
    "args.learning_rate = 0.0001\n",
    "args.batch_size = 64\n",
    "args.embed = 'timeF'\n",
    "args.activation = 'gelu'\n",
    "args.use_amp = False\n",
    "args.loss = 'mse'\n",
    "args.train_epochs = 20\n",
    "print('Args in experiment:')\n",
    "print(args)\n",
    "\n",
    "Exp = Exp_Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "executionInfo": {
     "elapsed": 11650,
     "status": "error",
     "timestamp": 1711876809698,
     "user": {
      "displayName": "deep_ learninng",
      "userId": "04264285591991528950"
     },
     "user_tz": -210
    },
    "id": "fJHeQNNs5Z_s",
    "outputId": "b19b8bce-2f1c-4c0c-abec-bfbdfa73cf28"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "train_times = []\n",
    "peak_memory_mb = []\n",
    "\n",
    "for ii in range(args.itr):\n",
    "    \n",
    "    setting = 'New_CLM_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "        args.model_id, args.model, args.data, args.features,\n",
    "        args.seq_len, args.label_len, args.pred_len,\n",
    "        args.d_model, args.n_heads, args.e_layers, args.d_layers,\n",
    "        args.d_ff, args.factor, args.embed, args.distil, args.des, ii)\n",
    "\n",
    "    exp = Exp(args)  \n",
    "\n",
    "    print(f'\\n>>>>>>> Start training : {setting} >>>>>>>>>>>>>>>>>>>>>>>>>>\\n')\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats(device=args.gpu)\n",
    "\n",
    "    start_train_time = time.time()\n",
    "    exp.train(setting)\n",
    "    end_train_time = time.time()\n",
    "\n",
    "    current_train_time = end_train_time - start_train_time\n",
    "    train_times.append(current_train_time)\n",
    "\n",
    "    current_peak_mem = torch.cuda.max_memory_allocated(device=args.gpu) / (1024 ** 2)\n",
    "    peak_memory_mb.append(current_peak_mem)\n",
    "\n",
    "    print(f\"Training Time: {current_train_time:.2f} seconds\")\n",
    "    print(f\"Peak GPU Memory: {current_peak_mem:.2f} MB\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\n--- Training Results across {args.itr} runs ---\")\n",
    "print(f\"Training Time (Mean ± Std): {np.mean(train_times):.2f} ± {np.std(train_times):.2f} s\")\n",
    "print(f\"Peak Memory (Mean ± Std):   {np.mean(peak_memory_mb):.2f} ± {np.std(peak_memory_mb):.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1711876809702,
     "user": {
      "displayName": "deep_ learninng",
      "userId": "04264285591991528950"
     },
     "user_tz": -210
    },
    "id": "OsTSj_IwAKjp"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "inference_times = []\n",
    "peak_memory_mb = []\n",
    "\n",
    "\n",
    "for ii in range(args.itr):\n",
    "    setting = 'New_CLM_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "        args.model_id, args.model, args.data, args.features,\n",
    "        args.seq_len, args.label_len, args.pred_len,\n",
    "        args.d_model, args.n_heads, args.e_layers, args.d_layers,\n",
    "        args.d_ff, args.factor, args.embed, args.distil, args.des, ii)\n",
    "\n",
    "    print(f\"\\n>>>>>>> Start testing : {setting} <<<<<<<<<<<<<<<<<<<<<<<<<<<\\n\")\n",
    "\n",
    "    exp = Exp(args)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats(device=device)\n",
    "\n",
    "    model_path = f'./checkpoints/{setting}/best_model.pth'\n",
    "    assert os.path.exists(model_path), f\"❌ Model file not found: {model_path}\"\n",
    "\n",
    "    print(f\"✅ Loading best model from {model_path}\")\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    exp.model.load_state_dict(checkpoint)\n",
    "    exp.model.to(device)\n",
    "    exp.model.eval()\n",
    "\n",
    "    start_test_time = time.time()\n",
    "    avg_mae, avg_mse, avg_rmse, avg_mape, avg_mspe, total_time, peak_mem = exp.test(setting, test=1)\n",
    "    end_test_time = time.time()\n",
    "\n",
    "    current_test_time = end_test_time - start_test_time\n",
    "    inference_times.append(current_test_time)\n",
    "\n",
    "    current_peak_mem = torch.cuda.max_memory_allocated(device=device) / (1024 ** 2)\n",
    "    peak_memory_mb.append(current_peak_mem)\n",
    "\n",
    "    print(f\"Inference Time: {current_test_time:.2f} seconds\")\n",
    "    print(f\"Peak GPU Memory: {current_peak_mem:.2f} MB\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\n--- Final Test Results across {args.itr} runs ---\")\n",
    "print(f\"Inference Time (Mean ± Std):  {np.mean(inference_times):.2f} ± {np.std(inference_times):.2f} s\")\n",
    "print(f\"Peak Memory (Mean ± Std):     {np.mean(peak_memory_mb):.2f} ± {np.std(peak_memory_mb):.2f} MB\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8ec1ed4803a557ac69aab47dceed289cc9effadaf04c1eb59c412c7bd577a542"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
